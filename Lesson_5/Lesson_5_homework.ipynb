{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим работу с данными, которые были использованы в ДЗ2 и 3, продолжим решать задачу обнаружения мошеннических транзакций, что позволит получить полное решение задачи / полный пайплайн.\n",
    "\n",
    "### Задание 0: \n",
    "Выбрать любую модель машнного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install missingno\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "from scipy.stats import probplot, ks_2samp\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import missingno as msno\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = 180000 rows, 394 cols\n",
      "test.shape = 100001 rows, 394 cols\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"assignment_2_train.csv\")\n",
    "test = pd.read_csv(\"assignment_2_test.csv\")\n",
    "\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "print(\"test.shape = {} rows, {} cols\".format(*test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"TransactionID\", inplace=True)\n",
    "X_train = train.drop(\"isFraud\", axis=1)\n",
    "y_train = train[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values(\"TransactionID\", inplace=True)\n",
    "X_test = test.drop(\"isFraud\", axis=1)\n",
    "y_test = test[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, shuffle=False, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes(exclude=[\"object\"])\n",
    "numerical_features = numerical_features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_eval(X_train, X_valid, X_test, y_train, y_valid, feats=numerical_features):\n",
    "    eval_set = [(X_valid[feats], y_valid)]\n",
    "    model = xgb.XGBClassifier(n_estimators=100, n_jobs=8)\n",
    "    model.fit(X_train[feats],\n",
    "            y_train,\n",
    "            eval_metric='auc',\n",
    "            eval_set=eval_set,\n",
    "            early_stopping_rounds=5)\n",
    "    \n",
    "    y_train_pred = model.predict_proba(X_train[feats])\n",
    "    print(f\"Train score (ROC_AUC): {roc_auc_score(y_train, y_train_pred[:, 1])}\")\n",
    "    y_valid_pred = model.predict_proba(X_valid[feats])\n",
    "    print(f\"Valid score (ROC_AUC): {roc_auc_score(y_valid, y_valid_pred[:, 1])}\")\n",
    "    y_test_pred = model.predict_proba(X_test[feats])\n",
    "    print(f\"Test  score (ROC_AUC): {roc_auc_score(y_test, y_test_pred[:, 1])}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69945\n",
      "[1]\tvalidation_0-auc:0.79227\n",
      "[2]\tvalidation_0-auc:0.83576\n",
      "[3]\tvalidation_0-auc:0.83572\n",
      "[4]\tvalidation_0-auc:0.83670\n",
      "[5]\tvalidation_0-auc:0.83706\n",
      "[6]\tvalidation_0-auc:0.83939\n",
      "[7]\tvalidation_0-auc:0.84944\n",
      "[8]\tvalidation_0-auc:0.85100\n",
      "[9]\tvalidation_0-auc:0.85545\n",
      "[10]\tvalidation_0-auc:0.83308\n",
      "[11]\tvalidation_0-auc:0.81001\n",
      "[12]\tvalidation_0-auc:0.82093\n",
      "[13]\tvalidation_0-auc:0.83149\n",
      "Train score (ROC_AUC): 0.8900934092842951\n",
      "Valid score (ROC_AUC): 0.8554492591505862\n",
      "Test  score (ROC_AUC): 0.8401148107316188\n"
     ]
    }
   ],
   "source": [
    "base_model = fit_eval(X_train, X_valid, X_test, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1: \n",
    "Признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transactionDT(X):\n",
    "    base_date = pd.to_datetime('2017-12-01')\n",
    "    X[\"TransactionDT\"] = base_date + pd.to_timedelta(X[\"TransactionDT\"], unit='s')\n",
    "    X[\"TransactionDT_Year\"] = X[\"TransactionDT\"].dt.year\n",
    "    X[\"TransactionDT_Month\"] = X[\"TransactionDT\"].dt.month\n",
    "    X[\"TransactionDT_WeekDay\"] = X[\"TransactionDT\"].dt.weekday\n",
    "    X[\"TransactionDT_Day\"] = X[\"TransactionDT\"].dt.day\n",
    "    X[\"TransactionDT_Hour\"] = X[\"TransactionDT\"].dt.hour\n",
    "    X[\"TransactionDT\"] = (X[\"TransactionDT\"].astype('int64')/1000000000).astype('int64')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = process_transactionDT(X_train)\n",
    "X_valid = process_transactionDT(X_valid)\n",
    "X_test = process_transactionDT(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = numerical_features + [\"TransactionDT_Year\", \"TransactionDT_Month\", \"TransactionDT_WeekDay\", \"TransactionDT_Day\", \"TransactionDT_Hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69945\n",
      "[1]\tvalidation_0-auc:0.79227\n",
      "[2]\tvalidation_0-auc:0.83578\n",
      "[3]\tvalidation_0-auc:0.83574\n",
      "[4]\tvalidation_0-auc:0.83675\n",
      "[5]\tvalidation_0-auc:0.83714\n",
      "[6]\tvalidation_0-auc:0.83946\n",
      "[7]\tvalidation_0-auc:0.84949\n",
      "[8]\tvalidation_0-auc:0.85104\n",
      "[9]\tvalidation_0-auc:0.85555\n",
      "[10]\tvalidation_0-auc:0.83228\n",
      "[11]\tvalidation_0-auc:0.83645\n",
      "[12]\tvalidation_0-auc:0.84455\n",
      "[13]\tvalidation_0-auc:0.85653\n",
      "[14]\tvalidation_0-auc:0.83950\n",
      "[15]\tvalidation_0-auc:0.84881\n",
      "[16]\tvalidation_0-auc:0.85451\n",
      "[17]\tvalidation_0-auc:0.85962\n",
      "[18]\tvalidation_0-auc:0.86272\n",
      "[19]\tvalidation_0-auc:0.86613\n",
      "[20]\tvalidation_0-auc:0.86897\n",
      "[21]\tvalidation_0-auc:0.87116\n",
      "[22]\tvalidation_0-auc:0.87108\n",
      "[23]\tvalidation_0-auc:0.87446\n",
      "[24]\tvalidation_0-auc:0.87464\n",
      "[25]\tvalidation_0-auc:0.87523\n",
      "[26]\tvalidation_0-auc:0.87597\n",
      "[27]\tvalidation_0-auc:0.87641\n",
      "[28]\tvalidation_0-auc:0.87684\n",
      "[29]\tvalidation_0-auc:0.87662\n",
      "[30]\tvalidation_0-auc:0.87683\n",
      "[31]\tvalidation_0-auc:0.87722\n",
      "[32]\tvalidation_0-auc:0.87433\n",
      "[33]\tvalidation_0-auc:0.87421\n",
      "[34]\tvalidation_0-auc:0.87288\n",
      "[35]\tvalidation_0-auc:0.87341\n",
      "Train score (ROC_AUC): 0.9461334898723922\n",
      "Valid score (ROC_AUC): 0.8772223517671749\n",
      "Test  score (ROC_AUC): 0.8256666606765054\n"
     ]
    }
   ],
   "source": [
    "model = fit_eval(X_train, X_valid, X_test, y_train, y_valid, feats=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат совсем немного, но стал лучше. Подозреваю, что это связано с тем, что хоть алгоритм может вывести какие-то временные зависимости (на выходных или перед праздниками, к примеру, поведение и обычных клиентов, и мошенников может меняться), но алгоритму это легче сделать с выделенными признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: \n",
    "Сделать конкатенацию признаков\n",
    "* card1 + card2;\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "Рассматривать их как категориальных признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenation(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    data['card_1_2'] = data['card1'].astype(np.str) + '_' + data['card2'].astype(np.str)\n",
    "    data['card_1_2_3_5'] = data['card_1_2'] + '_' + data['card3'].astype(np.str) + '_' + data['card5'].astype(np.str)\n",
    "    data['card_1_2_3_5_addr_1_2'] = data['card_1_2_3_5'] + '_' + data['addr1'].astype(np.str) + '_' + data['addr2'].astype(np.str)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_concat = concatenation(X_train)\n",
    "# X_valid_concat = concatenation(X_valid)\n",
    "\n",
    "# stata = model(X_train_concat, y_train, X_valid_concat, y_valid, operation= concatenation)\n",
    "# stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3: \n",
    "Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cards_feats_enc(data):\n",
    "    new_feats = []\n",
    "    for feat in [\"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\"]:\n",
    "        freq_encoder = data[feat].value_counts(normalize=True)\n",
    "        data[f\"{feat}_freq_enc\"] = data[feat].map(freq_encoder)\n",
    "        new_feats += [f\"{feat}_freq_enc\"]\n",
    "    return data, new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, new_feats = process_cards_feats_enc(X_train)\n",
    "X_valid, new_feats = process_cards_feats_enc(X_valid)\n",
    "X_test, new_feats = process_cards_feats_enc(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['card1_freq_enc',\n",
       " 'card2_freq_enc',\n",
       " 'card3_freq_enc',\n",
       " 'card4_freq_enc',\n",
       " 'card5_freq_enc',\n",
       " 'card6_freq_enc',\n",
       " 'addr1_freq_enc',\n",
       " 'addr2_freq_enc']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features += new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69880\n",
      "[1]\tvalidation_0-auc:0.79234\n",
      "[2]\tvalidation_0-auc:0.83462\n",
      "[3]\tvalidation_0-auc:0.83274\n",
      "[4]\tvalidation_0-auc:0.83408\n",
      "[5]\tvalidation_0-auc:0.83608\n",
      "[6]\tvalidation_0-auc:0.83745\n",
      "[7]\tvalidation_0-auc:0.84590\n",
      "[8]\tvalidation_0-auc:0.85197\n",
      "[9]\tvalidation_0-auc:0.85872\n",
      "[10]\tvalidation_0-auc:0.83012\n",
      "[11]\tvalidation_0-auc:0.84714\n",
      "[12]\tvalidation_0-auc:0.81837\n",
      "[13]\tvalidation_0-auc:0.82810\n",
      "Train score (ROC_AUC): 0.8943290986990793\n",
      "Valid score (ROC_AUC): 0.8587190485277483\n",
      "Test  score (ROC_AUC): 0.8474646251738036\n"
     ]
    }
   ],
   "source": [
    "model = fit_eval(X_train, X_valid, X_test, y_train, y_valid, feats=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного увеличилось качество модели, похоже, что введённые признаки полезны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4: \n",
    "Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggs(data, groupby_id, aggs=None, features=None):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    if aggs != None:\n",
    "        data_grouped_num = data.groupby(groupby_id)\n",
    "        stats_num = data_grouped_num.agg(aggs)\n",
    "        stats_num.columns = [f\"{feature}_{stat}\" for feature, stat in stats_num]\n",
    "        stats_num = stats_num.reset_index()\n",
    "        data = data.merge(stats_num, how='left', on=groupby_id)\n",
    "    \n",
    "    if features != None:\n",
    "        categorical = data[features].copy()\n",
    "        le = LabelEncoder()\n",
    "        for feature in features:\n",
    "            cat_value = list(categorical[feature].values.astype('str'))\n",
    "            le.fit(cat_value)\n",
    "            categorical[feature] = le.transform(cat_value)\n",
    "        categorical[groupby_id] = data[groupby_id]\n",
    "        data_grouped_cat = categorical.groupby(groupby_id)\n",
    "        stats_cat = data_grouped_cat.agg({col: [\"mean\", \"sum\"] for col in features})\n",
    "        stats_cat.columns = [f\"{feature}_{stat}\" for feature, stat in stats_cat]\n",
    "        stats_cat = stats_cat.reset_index()\n",
    "        data = data.merge(stats_cat, how='left', on=groupby_id)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data_concat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e797a70b0567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgroupby_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"TransactionAmt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mX_data_agg_amt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_aggs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroupby_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mX_lb_agg_amt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_aggs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_lb_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroupby_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_data_concat' is not defined"
     ]
    }
   ],
   "source": [
    "aggs = {\"card1\": [np.mean, np.std],\n",
    "        \"card2\": [np.mean, np.std],\n",
    "        \"card3\": [np.mean, np.std],\n",
    "        \"card5\": [np.mean, np.std],\n",
    "        \"addr1\": [np.mean, np.std],\n",
    "        \"addr2\": [np.mean, np.std]\n",
    "        }\n",
    "\n",
    "features = [\"card4\", \"card6\", \"card_1_2\", \"card_1_2_3_5\", \"card_1_2_3_5_addr_1_2\"]\n",
    "\n",
    "groupby_id = \"TransactionAmt\"\n",
    "    \n",
    "X_data_agg_amt = create_aggs(X_data_concat, groupby_id, aggs, features)\n",
    "X_lb_agg_amt = create_aggs(X_lb_concat, groupby_id, aggs, features)\n",
    "\n",
    "stata = evaluation_model(X_data_agg_amt, y_data, X_lb_agg_amt, y_lb, operation='aggregating_TransactionAmt')\n",
    "stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69880\n",
      "[1]\tvalidation_0-auc:0.79234\n",
      "[2]\tvalidation_0-auc:0.83462\n",
      "[3]\tvalidation_0-auc:0.83274\n",
      "[4]\tvalidation_0-auc:0.83408\n",
      "[5]\tvalidation_0-auc:0.83608\n",
      "[6]\tvalidation_0-auc:0.83745\n",
      "[7]\tvalidation_0-auc:0.84590\n",
      "[8]\tvalidation_0-auc:0.85197\n",
      "[9]\tvalidation_0-auc:0.85872\n",
      "[10]\tvalidation_0-auc:0.83012\n",
      "[11]\tvalidation_0-auc:0.84714\n",
      "[12]\tvalidation_0-auc:0.81837\n",
      "[13]\tvalidation_0-auc:0.82810\n",
      "[14]\tvalidation_0-auc:0.83895\n",
      "Train score (ROC_AUC): 0.8943290986990793\n",
      "Valid score (ROC_AUC): 0.8587190485277483\n",
      "Test  score (ROC_AUC): 0.8474646251738036\n"
     ]
    }
   ],
   "source": [
    "model = fit_eval(X_train, X_valid, X_test, y_train, y_valid, feats=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменения минимальны, похоже модели всё равно, в логарифмическом масштабе подаётся величина или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5: \n",
    "Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data_concat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-966443efec26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgroupby_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D15\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_data_agg_d15\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_aggs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroupby_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_lb_agg_d15\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_aggs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_lb_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroupby_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_data_concat' is not defined"
     ]
    }
   ],
   "source": [
    "groupby_id = \"D15\"\n",
    "\n",
    "X_data_agg_d15 = create_aggs(X_data_concat, groupby_id, aggs, features)\n",
    "X_lb_agg_d15 = create_aggs(X_lb_concat, groupby_id, aggs, features)\n",
    "\n",
    "stata = evaluation_model(X_data_agg_d15, y_data, X_lb_agg_d15, y_lb, operation='aggregating_D15')\n",
    "stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6: \n",
    "выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_TransactionAmt(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    data['TransactionAmt_whole'] = data['TransactionAmt']//1\n",
    "    data['TransactionAmt_frac'] = data['TransactionAmt']%1\n",
    "    data['TransactionAmt_log'] = np.log2(data['TransactionAmt'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-429964725665>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_data_trans_amt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_TransactionAmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_lb_trans_amt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_TransactionAmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_lb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_trans_amt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_lb_trans_amt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_lb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'transform_TransactionAmt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_data' is not defined"
     ]
    }
   ],
   "source": [
    "X_data_trans_amt = transform_TransactionAmt(X_data)\n",
    "X_lb_trans_amt = transform_TransactionAmt(X_lb)\n",
    "\n",
    "stata = evaluation_model(X_data_trans_amt, y_data, X_lb_trans_amt, y_lb, operation='transform_TransactionAmt')\n",
    "stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим работу с данными, которые были использованы в ДЗ2 и 3, продолжим решать задачу обнаружения мошеннических транзакций, что позволит получить полное решение задачи / полный пайплайн.\n",
    "\n",
    "### Задание 0: \n",
    "Выбрать любую модель машнного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "from scipy.stats import probplot, ks_2samp\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import missingno as msno\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import catboost as catb\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = 180000 rows, 394 cols\n",
      "test.shape = 100001 rows, 394 cols\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"assignment_2_train.csv\")\n",
    "test = pd.read_csv(\"assignment_2_test.csv\")\n",
    "\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "print(\"test.shape = {} rows, {} cols\".format(*test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"TransactionID\", inplace=True)\n",
    "X_train = train.drop(\"isFraud\", axis=1)\n",
    "y_train = train[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values(\"TransactionID\", inplace=True)\n",
    "X_test = test.drop(\"isFraud\", axis=1)\n",
    "y_test = test[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, shuffle=False, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes(exclude=[\"object\"])\n",
    "numerical_features = numerical_features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_eval(X_train, X_valid, X_test, y_train, y_valid, feats=numerical_features):\n",
    "    eval_set = [(X_valid[feats], y_valid)]\n",
    "    model = xgb.XGBClassifier(n_estimators=100, n_jobs=8)\n",
    "    model.fit(X_train[feats],\n",
    "            y_train,\n",
    "            eval_metric='auc',\n",
    "            eval_set=eval_set,\n",
    "            early_stopping_rounds=5)\n",
    "    \n",
    "    y_train_pred = model.predict_proba(X_train[feats])\n",
    "    print(f\"Train score (ROC_AUC): {roc_auc_score(y_train, y_train_pred[:, 1])}\")\n",
    "    y_valid_pred = model.predict_proba(X_valid[feats])\n",
    "    print(f\"Valid score (ROC_AUC): {roc_auc_score(y_valid, y_valid_pred[:, 1])}\")\n",
    "    y_test_pred = model.predict_proba(X_test[feats])\n",
    "    print(f\"Test  score (ROC_AUC): {roc_auc_score(y_test, y_test_pred[:, 1])}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69945\n",
      "[1]\tvalidation_0-auc:0.79227\n",
      "[2]\tvalidation_0-auc:0.83576\n",
      "[3]\tvalidation_0-auc:0.83572\n",
      "[4]\tvalidation_0-auc:0.83670\n",
      "[5]\tvalidation_0-auc:0.83706\n",
      "[6]\tvalidation_0-auc:0.83939\n",
      "[7]\tvalidation_0-auc:0.84944\n",
      "[8]\tvalidation_0-auc:0.85100\n",
      "[9]\tvalidation_0-auc:0.85545\n",
      "[10]\tvalidation_0-auc:0.83308\n",
      "[11]\tvalidation_0-auc:0.81001\n",
      "[12]\tvalidation_0-auc:0.82093\n",
      "[13]\tvalidation_0-auc:0.83149\n",
      "[14]\tvalidation_0-auc:0.84480\n",
      "Train score (ROC_AUC): 0.8900934092842951\n",
      "Valid score (ROC_AUC): 0.8554492591505862\n",
      "Test  score (ROC_AUC): 0.8401148107316188\n"
     ]
    }
   ],
   "source": [
    "base_model = fit_eval(X_train, X_valid, X_test, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1: \n",
    "Признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transactionDT(X):\n",
    "    base_date = pd.to_datetime('2017-12-01')\n",
    "    X[\"TransactionDT\"] = base_date + pd.to_timedelta(X[\"TransactionDT\"], unit='s')\n",
    "    X[\"TransactionDT_Year\"] = X[\"TransactionDT\"].dt.year\n",
    "    X[\"TransactionDT_Month\"] = X[\"TransactionDT\"].dt.month\n",
    "    X[\"TransactionDT_WeekDay\"] = X[\"TransactionDT\"].dt.weekday\n",
    "    X[\"TransactionDT_Day\"] = X[\"TransactionDT\"].dt.day\n",
    "    X[\"TransactionDT_Hour\"] = X[\"TransactionDT\"].dt.hour\n",
    "    X[\"TransactionDT\"] = (X[\"TransactionDT\"].astype('int64')/1000000000).astype('int64')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = process_transactionDT(X_train)\n",
    "X_valid = process_transactionDT(X_valid)\n",
    "X_test = process_transactionDT(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = numerical_features + [\"TransactionDT_Year\", \"TransactionDT_Month\", \"TransactionDT_WeekDay\", \"TransactionDT_Day\", \"TransactionDT_Hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69945\n",
      "[1]\tvalidation_0-auc:0.79227\n",
      "[2]\tvalidation_0-auc:0.83578\n",
      "[3]\tvalidation_0-auc:0.83574\n",
      "[4]\tvalidation_0-auc:0.83675\n",
      "[5]\tvalidation_0-auc:0.83714\n",
      "[6]\tvalidation_0-auc:0.83946\n",
      "[7]\tvalidation_0-auc:0.84949\n",
      "[8]\tvalidation_0-auc:0.85104\n",
      "[9]\tvalidation_0-auc:0.85555\n",
      "[10]\tvalidation_0-auc:0.83228\n",
      "[11]\tvalidation_0-auc:0.83645\n",
      "[12]\tvalidation_0-auc:0.84455\n",
      "[13]\tvalidation_0-auc:0.85653\n",
      "[14]\tvalidation_0-auc:0.83950\n",
      "[15]\tvalidation_0-auc:0.84881\n",
      "[16]\tvalidation_0-auc:0.85451\n",
      "[17]\tvalidation_0-auc:0.85962\n",
      "[18]\tvalidation_0-auc:0.86272\n",
      "[19]\tvalidation_0-auc:0.86613\n",
      "[20]\tvalidation_0-auc:0.86897\n",
      "[21]\tvalidation_0-auc:0.87116\n",
      "[22]\tvalidation_0-auc:0.87108\n",
      "[23]\tvalidation_0-auc:0.87446\n",
      "[24]\tvalidation_0-auc:0.87464\n",
      "[25]\tvalidation_0-auc:0.87523\n",
      "[26]\tvalidation_0-auc:0.87597\n",
      "[27]\tvalidation_0-auc:0.87641\n",
      "[28]\tvalidation_0-auc:0.87684\n",
      "[29]\tvalidation_0-auc:0.87662\n",
      "[30]\tvalidation_0-auc:0.87683\n",
      "[31]\tvalidation_0-auc:0.87722\n",
      "[32]\tvalidation_0-auc:0.87433\n",
      "[33]\tvalidation_0-auc:0.87421\n",
      "[34]\tvalidation_0-auc:0.87288\n",
      "[35]\tvalidation_0-auc:0.87341\n",
      "[36]\tvalidation_0-auc:0.87285\n",
      "Train score (ROC_AUC): 0.9461334898723922\n",
      "Valid score (ROC_AUC): 0.8772223517671749\n",
      "Test  score (ROC_AUC): 0.8256666606765054\n"
     ]
    }
   ],
   "source": [
    "model = fit_eval(X_train, X_valid, X_test, y_train, y_valid, feats=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат совсем немного, но стал лучше. Подозреваю, что это связано с тем, что хоть алгоритм может вывести какие-то временные зависимости (на выходных или перед праздниками, к примеру, поведение и обычных клиентов, и мошенников может меняться), но алгоритму это легче сделать с выделенными признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: \n",
    "Сделать конкатенацию признаков\n",
    "* card1 + card2;\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "Рассматривать их как категориальных признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3: \n",
    "Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cards_feats_enc(data):\n",
    "    new_feats = []\n",
    "    for feat in [\"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\"]:\n",
    "        freq_encoder = data[feat].value_counts(normalize=True)\n",
    "        data[f\"{feat}_freq_enc\"] = data[feat].map(freq_encoder)\n",
    "        new_feats += [f\"{feat}_freq_enc\"]\n",
    "    return data, new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, new_feats = process_cards_feats_enc(X_train)\n",
    "X_valid, new_feats = process_cards_feats_enc(X_valid)\n",
    "X_test, new_feats = process_cards_feats_enc(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['card1_freq_enc',\n",
       " 'card2_freq_enc',\n",
       " 'card3_freq_enc',\n",
       " 'card4_freq_enc',\n",
       " 'card5_freq_enc',\n",
       " 'card6_freq_enc',\n",
       " 'addr1_freq_enc',\n",
       " 'addr2_freq_enc']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features += new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69880\n",
      "[1]\tvalidation_0-auc:0.79234\n",
      "[2]\tvalidation_0-auc:0.83462\n",
      "[3]\tvalidation_0-auc:0.83274\n",
      "[4]\tvalidation_0-auc:0.83408\n",
      "[5]\tvalidation_0-auc:0.83608\n",
      "[6]\tvalidation_0-auc:0.83745\n",
      "[7]\tvalidation_0-auc:0.84590\n",
      "[8]\tvalidation_0-auc:0.85197\n",
      "[9]\tvalidation_0-auc:0.85872\n",
      "[10]\tvalidation_0-auc:0.83012\n",
      "[11]\tvalidation_0-auc:0.84714\n",
      "[12]\tvalidation_0-auc:0.81837\n",
      "[13]\tvalidation_0-auc:0.82810\n",
      "Train score (ROC_AUC): 0.8943290986990793\n",
      "Valid score (ROC_AUC): 0.8587190485277483\n",
      "Test  score (ROC_AUC): 0.8474646251738036\n"
     ]
    }
   ],
   "source": [
    "model = fit_eval(X_train, X_valid, X_test, y_train, y_valid, feats=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного увеличилось качество модели, похоже, что введённые признаки полезны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4: \n",
    "Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5: \n",
    "Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6: \n",
    "выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
